{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94802ca5-3d0d-4f0d-8c35-26c3a0d1a115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "connectionString = \"<connection-string>\"\n",
    "eventHubName = \"<event-hub>\"\n",
    "\n",
    "ehConf = {\n",
    "  'eventhubs.connectionString' : sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(connectionString),\n",
    "  'eventhubs.eventHubName': eventHubName\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc67e2c8-c297-4c79-9d97-ef661a5d52a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tripRequestsRaw = spark.readStream \\\n",
    "    .format(\"eventhubs\") \\\n",
    "    .options(**ehConf) \\\n",
    "    .load() \n",
    "\n",
    "tripRequestsRaw.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65cb738-ae02-443d-a8f9-75dc37e2dada",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "json_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"xstart\", IntegerType()),\n",
    "    StructField(\"ystart\", IntegerType()),\n",
    "    StructField(\"xend\", IntegerType()),\n",
    "    StructField(\"yend\", IntegerType()),\n",
    "    StructField(\"ts\", TimestampType()),\n",
    "    StructField(\"source\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59a81cf-99b8-4732-b926-2688db116c3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tripRequests = tripRequestsRaw.withColumn(\"body\", col(\"body\").cast(\"string\"))\\\n",
    "    .withColumn(\"body\",from_json(col(\"body\"), json_schema))\\\n",
    "    .select(\"body.user_id\",\"body.xstart\", \"body.ystart\", \"body.xend\", \"body.yend\", \"body.ts\", \"body.source\")\n",
    "\n",
    "tripRequests.display()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25817124-4f2a-41ca-9847-77508a65e7ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/demandNavigator/ has been unmounted.\nOut[60]: [FileInfo(path='dbfs:/mnt/demandNavigator/area_requests/', name='area_requests/', size=0, modificationTime=1711962893000),\n FileInfo(path='dbfs:/mnt/demandNavigator/geographic data.csv', name='geographic data.csv', size=253, modificationTime=1711970442000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.unmount(\"/mnt/demandNavigator/\")\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\": \"a53ac462-aec8-490a-96d7-d36e1155d572\",\n",
    "          \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope=\"dnkey\",key=\"dbsecret\"),\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/7f77ffeb-3a63-436d-85f5-46b045efa8d7/oauth2/token\"}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://landingarea@dnadlg2.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/demandNavigator/\",\n",
    "  extra_configs = configs)\n",
    "\n",
    "dbutils.fs.ls(\"/mnt/demandNavigator/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe0d3732-57ad-4840-b5da-12f35fba0b91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- RegionID: integer (nullable = true)\n |-- RegionName: string (nullable = true)\n |-- startx: integer (nullable = true)\n |-- endx: integer (nullable = true)\n |-- starty: integer (nullable = true)\n |-- endy: integer (nullable = true)\n\n+--------+-------------------+------+----+------+----+\n|RegionID|         RegionName|startx|endx|starty|endy|\n+--------+-------------------+------+----+------+----+\n|       1|   Crescenta Valley|     1|   2|     1|   2|\n|       2|           Downtown|     1|   2|     3|   4|\n|       3|           Eastside|     1|   2|     5|   6|\n|       4|        Harbor Area|     3|   4|     1|   2|\n|       5|  Greater Hollywood|     3|   4|     3|   4|\n|       6|       Northeast LA|     3|   4|     5|   6|\n|       7|       Northwest LA|     5|   6|     1|   2|\n|       8|San Fernando Valley|     5|   6|     3|   4|\n|       9|           South LA|     5|   6|     5|   6|\n+--------+-------------------+------+----+------+----+\n\n"
     ]
    }
   ],
   "source": [
    "areasInfo = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/mnt/demandNavigator/geographic data.csv\")\n",
    "\n",
    "areasInfo.printSchema()\n",
    "\n",
    "areasInfo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5043da21-7420-4fa7-a5a7-c932d44fb80b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "areaRequests = tripRequests.join(areasInfo,(tripRequests.xstart<=areasInfo.startx)&(tripRequests.xend>=areasInfo.startx)&(tripRequests.ystart<=areasInfo.starty)&(tripRequests.yend>=areasInfo.starty)).select(tripRequests.user_id,areasInfo.RegionID,areasInfo.RegionName,tripRequests.ts)\n",
    "areaRequests.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ec9c0d-42e5-49ee-aade-b7a5d9ab42b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "areaRequests.printSchema()\n",
    "\n",
    "areaRequestsAgg = areaRequests.withWatermark(\"ts\", \"60 minutes\").groupBy(window(col(\"ts\"),\"10 minutes\"),areaRequests.RegionID,areaRequests.RegionName).agg(count(areaRequests.user_id).alias(\"totalRequests\"))\n",
    "\n",
    "json_schema = StructType([\n",
    "    StructField(\"start\", TimestampType()),\n",
    "    StructField(\"end\", TimestampType())\n",
    "])\n",
    "\n",
    "areaRequestsAgg = areaRequestsAgg.withColumn(\"ts_start\",col(\"window.start\"))\n",
    "areaRequestsAgg.printSchema()\n",
    "areaRequestsAgg.display()\n",
    "#areaRequestsAgg = areaRequestsAgg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d8dc3d-dc48-4112-b891-77d67a5789c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[69]: <pyspark.sql.streaming.query.StreamingQuery at 0x7f8da6d32940>"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.streaming import *\n",
    "\n",
    "#spark.sql(\"drop table streaming.area_requests.totalrequests\")\n",
    "\n",
    "areaRequestsAgg.writeStream\\\n",
    "    .option(\"checkpointLocation\", \"/mnt/demandNavigator/area_requests/\")\\\n",
    "    .outputMode(\"complete\")\\\n",
    "    .format(\"delta\")\\\n",
    "    .toTable(\"streaming.area_requests.totalrequests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c61651a4-5ff9-4d03-a8a6-42635a984829",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-01 16:50:00\n+-------------------+-------------------+-------------+\n|           ts_start|         RegionName|totalRequests|\n+-------------------+-------------------+-------------+\n|2024-04-01 16:50:00|  Greater Hollywood|            9|\n|2024-04-01 16:50:00|San Fernando Valley|            8|\n|2024-04-01 16:50:00|       Northwest LA|            7|\n|2024-04-01 16:50:00|       Northeast LA|            5|\n|2024-04-01 16:50:00|           South LA|            5|\n|2024-04-01 16:50:00|        Harbor Area|            5|\n|2024-04-01 16:50:00|   Crescenta Valley|            3|\n|2024-04-01 16:50:00|           Downtown|            3|\n|2024-04-01 16:50:00|           Eastside|            3|\n+-------------------+-------------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select max(ts_start) from streaming.area_requests.totalrequests\")\n",
    "max_ts = df.rdd.collect()[0]['max(ts_start)']\n",
    "print(max_ts)\n",
    "\n",
    "df2 = spark.sql(\"select ts_start,RegionName,totalRequests from streaming.area_requests.totalrequests where ts_start='\"+str(max_ts)+\"' order by totalRequests desc\")\n",
    "df2.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Trip requests transformation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
